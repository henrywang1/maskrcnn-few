{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import skimage.io as io\n",
    "import torch\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image, ImageOps\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "\n",
    "def add_border(input_image, border, color):\n",
    "    #img = Image.open(input_image)\n",
    "    if isinstance(border, int) or isinstance(border, tuple):\n",
    "        #debug# print(input_image, border, color)\n",
    "        if not input_image.mode == 'RGB':\n",
    "            rgbimg = Image.new(\"RGB\", input_image.size)\n",
    "            rgbimg.paste(input_image)\n",
    "            input_image = rgbimg\n",
    "        bimg = ImageOps.expand(input_image, border=border, fill=color)\n",
    "    else:\n",
    "        raise RuntimeError('Border is not an integer or tuple!')\n",
    "    return bimg\n",
    "\n",
    "\n",
    "def combine(query, support):\n",
    "    w1, h1 = query.size\n",
    "    w2, h2 = support.size\n",
    "    if w2 > w1:\n",
    "        support.resize(w1, h2*w1/w2)\n",
    "        w2, h2 = support.size\n",
    "    new_img = Image.new('RGB', (w1, h1+h2))\n",
    "    y_offset = 0\n",
    "    new_img.paste(support, (0, 0))\n",
    "    new_img.paste(query, (0, h2))\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def combine_images(images):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "    new_img = Image.new('RGBA', (total_width, max_height), (255, 0, 0, 0))\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        new_img.paste(im, (x_offset, 0))\n",
    "        x_offset += im.size[0]\n",
    "    # patch_box = Rectangle((bbox_x, bbox_y), bbox_w, bbox_h, linewidth=0, linestyle=\"dashed\", alpha=0, facecolor=\"none\")\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def get_one_croped_image(query_img_id, target_cat=None, cids=None, output_dir=\"\", json_to_cid=None):\n",
    "    support_ids = pair_df[pair_df.img_id ==\n",
    "        query_img_id].support_ann_ids.values[0]\n",
    "    support_anns = [\n",
    "        ann for ann in all_support_anns if ann[\"id\"] in support_ids]\n",
    "    global cat_f\n",
    "    if target_cat:\n",
    "        support_anns = [\n",
    "            ann for ann in support_anns if ann[\"category_id\"] in target_cat]\n",
    "    if cids:\n",
    "        support_anns = [\n",
    "            ann for ann in support_anns if ann[\"category_id\"] in cids]\n",
    "\n",
    "    support_ids = [ann[\"id\"] for ann in support_anns]\n",
    "    # support_cids = [ann[\"category_id\"] for ann in support_anns]\n",
    "    # cropped_boxes = []\n",
    "    return support_anns, support_ids\n",
    "#     for sid, support_ann in zip(support_ids, support_anns):\n",
    "#         img = coco_s.loadImgs(support_ann['image_id'])[0]\n",
    "#         #lvis use the example from train\n",
    "#         img_file = '../datasets/coco/train2017/%s'%img['file_name']\n",
    "#         I = Image.open(img_file)\n",
    "#         [x, y, w, h] = support_ann[\"bbox\"]\n",
    "#         box = [x, y, x+w, y+h]\n",
    "#         cropped_box = I.crop(box)\n",
    "#         box_size = cropped_box.size\n",
    "#         # print(box_size)\n",
    "#         long_side = max(box_size)\n",
    "#         scaling_factor = 300/long_side\n",
    "#         new_size = (int(box_size[0]*scaling_factor), int(box_size[1]*scaling_factor))\n",
    "#         cropped_box=cropped_box.resize(new_size)\n",
    "\n",
    "#         #if support_ann[\"category_id\"] in cat_r:\n",
    "#         color = (255, 0, 0)\n",
    "#         #elif support_ann[\"category_id\"] in cat_c:\n",
    "#         #    color = (0,255,0)\n",
    "#         #else:\n",
    "#         #    color = (0,0,255)\n",
    "#         # cropped_box = add_border(cropped_box, 5, color)\n",
    "# #       #plt.savefig('{0}/output-{1}-{2}.png'.format(root, img['id'], classes), dpi=300, bbox_inches='tight',pad_inches = 0)\n",
    "#         cropped_boxes.append(cropped_box)\n",
    "#         cropped_box.save(\"{0}{1}.png\".format(output_dir, sid))\n",
    "#     return combine_images(cropped_boxes), support_cids\n",
    "\n",
    "\n",
    "def get_image_and_th(result, target_cat):\n",
    "    img_score = defaultdict()\n",
    "    img_thresholds = defaultdict()\n",
    "    for item in result:\n",
    "        # consider iouThr 0.5\n",
    "        if target_cat:\n",
    "            E = [i for i in item if i[\"category_id\"] in target_cat]\n",
    "        else:\n",
    "            E = item\n",
    "        if not E:\n",
    "            continue\n",
    "        dtScores = np.concatenate([e['dtScores'] for e in E])\n",
    "        # dtScores = np.stack(E['dtScores'])\n",
    "        inds = np.argsort(-dtScores, kind='mergesort')\n",
    "\n",
    "        dtScoresSorted = dtScores[inds]\n",
    "        dtm = np.concatenate([e['dtMatches'][0] for e in E])[inds]\n",
    "        dtIg = np.concatenate([e['dtIgnore'][0] for e in E])[inds]\n",
    "        #dtm = np.stack([E['dtMatches'][0] for e in E])[inds]\n",
    "#         dtm  = np.stack([e[0] for e in E['dtMatches']])[inds]\n",
    "#         dtIg = np.stack([e[0] for e in E['dtIgnore']])[inds]\n",
    "        tps = np.logical_and(dtm,  np.logical_not(dtIg))\n",
    "        fps = np.logical_and(np.logical_not(dtm), np.logical_not(dtIg))\n",
    "        tp_sum = np.cumsum(tps).astype(dtype=np.float)\n",
    "        fp_sum = np.cumsum(fps).astype(dtype=np.float)\n",
    "\n",
    "        tp = np.array(tp_sum)\n",
    "        fp = np.array(fp_sum)\n",
    "        npig = len(tp)\n",
    "        rc = tp / npig\n",
    "        pr = tp / (fp+tp+np.spacing(1))\n",
    "        q = np.zeros((R,))\n",
    "        ss = np.zeros((R,))\n",
    "\n",
    "        try:\n",
    "            for ri, pi in enumerate(inds):\n",
    "                q[ri] = pr[pi]\n",
    "                ss[ri] = dtScoresSorted[pi]\n",
    "        except:\n",
    "            pass\n",
    "        beta = 0.5\n",
    "        f1 = ((1+beta**2)*pr*rc)/(beta**2*pr+rc)\n",
    "        if not pr.any() or not rc.any() or np.all(np.isnan(f1)):\n",
    "            continue\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        precision = np.array(q)\n",
    "        scores = np.array(ss)\n",
    "        mean_precision = np.mean(precision)\n",
    "        mean_precision = np.max(f1)\n",
    "        image_id = [i[\"image_id\"] for i in E][0]\n",
    "        img_score[image_id] = mean_precision\n",
    "        th = dtScoresSorted[np.nanargmax(f1)] - 0.00001\n",
    "        img_thresholds[image_id] = th\n",
    "    return img_score, img_thresholds\n",
    "\n",
    "\n",
    "def get_resize_from_size(box_size, max_size):\n",
    "    long_side = max(box_size)\n",
    "    scaling_factor = max_size/long_side\n",
    "    new_size = (int(box_size[0]*scaling_factor),\n",
    "                int(box_size[1]*scaling_factor))\n",
    "    return new_size\n",
    "\n",
    "\n",
    "def save_outputs(imgIds, thresholds, root, cocoGT, cocoDt, target_cat=None,):\n",
    "    json_category_id_to_contiguous_id = {\n",
    "        v: i + 1 for i, v in enumerate(coco.getCatIds())\n",
    "    }\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "    images = cocoDt.loadImgs(imgIds)\n",
    "    counter = 0\n",
    "\n",
    "    for img, th in zip(images, thresholds):\n",
    "        #if counter > 50:\n",
    "        #    break\n",
    "        output_dir = root+\"/\"+str(img['id']) + \"/\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        # print(output_dir)\n",
    "        annIds = cocoDt.getAnnIds(img['id'], iscrowd=None)\n",
    "        anns = cocoDt.loadAnns(annIds)\n",
    "        if target_cat:\n",
    "            anns = [a for a in anns if a[\"category_id\"] in target_cat]\n",
    "        anns = [a for a in anns if a[\"score\"] > th]\n",
    "        # anns = [a for a in anns if a[\"category_id\"]==1]\n",
    "        if len(anns) == 0:\n",
    "            print(\"no annotations\")\n",
    "            continue\n",
    "        if target_cat:\n",
    "            cids = [ann[\"category_id\"]\n",
    "                for ann in anns if ann[\"category_id\"] in target_cat]\n",
    "        else:\n",
    "            cids = [ann[\"category_id\"] for ann in anns if ann[\"category_id\"]]\n",
    "        #if (not(set(cids)&set(cat_r)) and not(set(cids)&set(cat_c))):\n",
    "        #if not(set(cids)&set(cat_r)):\n",
    "        #    continue\n",
    "        #if not len(set(cids)) == 1: # and not len(set(cids)) == 3:\n",
    "        #     continue\n",
    "        # print((set(cids)&set(cat_r)),(set(cids)&set(cat_c)))\n",
    "        #if target_cat and (not set(cids) & set(target_cat)):\n",
    "        #    print(\"no target categories\")\n",
    "        #    continue\n",
    "        if not cids:\n",
    "            print(\"no target categories\")\n",
    "            continue\n",
    "        counter += 1\n",
    "        if target_cat:\n",
    "            anns = [ann for ann in anns if ann[\"category_id\"] in target_cat]\n",
    "\n",
    "        plt.axis('off')\n",
    "        I = Image.open('../datasets/coco/val2017/%s' % img['file_name'])\n",
    "        # from shutil import copyfile\n",
    "        # copyfile('../datasets/coco/val2017/%s'%img['file_name'], output_dir+img['file_name'])\n",
    "        max_size = max(I.size)\n",
    "        w, h = I.size\n",
    "#         if max_size > 1000.0:\n",
    "#             scale = 1000.0/max_size\n",
    "#             w = int(w*scale)\n",
    "#             h = int(h*scale)\n",
    "#             I = I.resize(w, h)\n",
    "#             w, h = I.size\n",
    "        scale = 800/h\n",
    "        w = int(w*scale)\n",
    "        h = int(h*scale)\n",
    "        figsize = (w/300, h/300)\n",
    "        # I = I.resize((w, h))\n",
    "        # plt.autoscale(False)\n",
    "        plt.imshow(I);  # plt.axis('off')\n",
    "        plt.savefig(output_dir+img['file_name'], dpi=300,\n",
    "                    bbox_inches='tight', pad_inches=0, figsize=figsize)\n",
    "        # draw GT anns\n",
    "        annIds_gt = cocoGt.getAnnIds(img['id'], iscrowd=None)\n",
    "        anns_gt = cocoGt.loadAnns(annIds_gt)\n",
    "        anns_gt = [ann for ann in anns_gt if ann[\"category_id\"] in set(cids)]\n",
    "        # anns_gt = [ann for ann in anns_gt if ann[\"iscrowd\"] == 0]\n",
    "        for i, ann in enumerate(anns_gt):\n",
    "            anns_gt[i][\"category_id\"] = json_category_id_to_contiguous_id[ann[\"category_id\"]]\n",
    "        coco.showAnns(anns_gt, class_names=class_names,\n",
    "                      show_mask=True,\n",
    "                      show_bbox=True,\n",
    "                      box_width=1,\n",
    "                      draw_caption=True,\n",
    "                      text_size=10,\n",
    "                     )\n",
    "\n",
    "        plt.savefig(output_dir + \"gt_\" + img['file_name'], dpi=300,\n",
    "                    bbox_inches='tight', pad_inches=0, figsize=figsize)\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.imshow(I)\n",
    "        draw_caption=True\n",
    "        # print([ann[\"category_id\"] for ann in anns])\n",
    "        for i, ann in enumerate(anns):\n",
    "            anns[i][\"category_id\"]=json_category_id_to_contiguous_id[ann[\"category_id\"]]\n",
    "        # print([ann[\"category_id\"] for ann in anns])\n",
    "        # assert False\n",
    "        coco.showAnns(anns, class_names=class_names,\n",
    "                      show_mask = True,\n",
    "                      show_bbox = True,\n",
    "                      box_width = 1,\n",
    "                      draw_caption = draw_caption,\n",
    "                      text_size = 10\n",
    "                     )\n",
    "        support_anns, support_ids= get_one_croped_image(\n",
    "            img['id'],\n",
    "            target_cat,\n",
    "            cids, output_dir,\n",
    "        )\n",
    "        support_cids = [ann[\"category_id\"] for ann in support_anns]\n",
    "        support_cids = [json_category_id_to_contiguous_id[c] for c in support_cids]\n",
    "        classes = [class_names[i] for i in support_cids]\n",
    "\n",
    "        for sid, support_ann, kls in zip(support_ids, support_anns, classes):\n",
    "            img = coco_s.loadImgs(support_ann['image_id'])[0]\n",
    "            img_file = '../datasets/coco/train2017/%s'%img['file_name']\n",
    "            I = Image.open(img_file)\n",
    "            [x, y, w, h] = support_ann[\"bbox\"]\n",
    "            box = [x, y, x+w, y+h]\n",
    "            cropped_box = I.crop(box)\n",
    "            box_size = cropped_box.size\n",
    "            # long_side = max(box_size)\n",
    "            # scaling_factor = 400/long_side\n",
    "            new_size = get_resize_from_size(max_size=400, box_size=box_size)\n",
    "            #(int(box_size[0]*scaling_factor), int(box_size[1]*scaling_factor))\n",
    "            # new_size = (400, 400)\n",
    "            cropped_box=cropped_box.resize(new_size)\n",
    "            cropped_box.save(\"{0}{1}.png\".format(output_dir, kls))        \n",
    "        \n",
    "        classes = ','.join(classes)\n",
    "        output_file = '{0}pred_{1}_{2}.png'.format(output_dir, img['id'], classes)\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight',pad_inches=0)\n",
    "        \n",
    "        # concat_img = combine_images([cropped_box[0], ])\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "# annFile = \"../datasets/coco/annotations/instances_val2017.json\"\n",
    "# annFile = \"../datasets/voc/VOC2012/Annotations/pascal_val2012_instance.json\"\n",
    "# lvis_v0.5_train.json_common_rare\n",
    "annFile = \"../datasets/lvis/annotations/lvis_v0.5_val.json_common_rare\"\n",
    "coco=COCO(annFile)\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "all_cats=[cat['name'] for cat in cats]\n",
    "# cat_r = [c[\"id\"] for c in cats if c[\"frequency\"] == \"r\"]\n",
    "# cat_c = [c[\"id\"] for c in cats if c[\"frequency\"] == \"c\"]\n",
    "# cat_f = [c[\"id\"] for c in cats if c[\"frequency\"] == \"f\"]\n",
    "class_names = [\"BG\"] + all_cats\n",
    "class_names  = [(re.sub(r\" ?\\([^)]+\\)\", \"\", c)) for c in class_names]\n",
    "annFile_s = annFile\n",
    "annFile_s = \"../datasets/lvis/annotations/lvis_v0.5_train.json_common_rare\"\n",
    "coco_s=COCO(annFile_s)\n",
    "all_support_anns = coco_s.dataset['annotations']\n",
    "# all_support_anns = [ann for ann in all_support_anns if ann[\"category_id\"] not in cat_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.56s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henrywang/.conda/envs/lvis/lib/python3.7/site-packages/ipykernel_launcher.py:57: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "/home/henrywang/.conda/envs/lvis/lib/python3.7/site-packages/ipykernel_launcher.py:149: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "no annotations\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# i = [a[\"id\"] for i, a in enumerate(anns[\"categories\"]) if i % 4 == (split-1)]\n",
    "# i = [a[\"id\"] for i, a in enumerate(anns[\"categories\"]) if not i % 4 == (split-1)]\n",
    "cids = coco.getCatIds()\n",
    "for i in range(1):\n",
    "    #if i < 4:\n",
    "    # target_cat = [k for j, k in enumerate(cids) if not j%4 == (i-1)]\n",
    "    # target_cat = [1, 3, 18, 20]\n",
    "    target_cat = None\n",
    "    #print(target_cat)\n",
    "    #continue\n",
    "    #else:\n",
    "    #    target_cat = [j for j in range(1, 81) if j%4 == 0]\n",
    "    # log_folder = \"lvis_val_cocostyle_test_{0}\".format(i)\n",
    "    # model_path = \"../models/coco_{0}_mil12_aff005\".format(i)\n",
    "    # log_folder = \"inference/coco_2017_val\"\n",
    "    model_path = \"../models/lvis_mil12_aff005_test\"\n",
    "    log_folder = \"inference/lvis_val_cocostyle\"\n",
    "    pair_df_file = \"{0}/features/all_pair_df.pickle\".format(model_path)\n",
    "    with open(pair_df_file, \"rb\") as f:\n",
    "        pair_df = pickle.load(f)\n",
    "    seg_file = \"{0}/{1}/segm.json\".format(model_path, log_folder)\n",
    "    cocoGt = COCO(annFile)\n",
    "    cocoDt = coco.loadRes(seg_file)\n",
    "    # coco = cocoDt\n",
    "    log_file = model_path + \"/\" + log_folder + \"/coco_evaluate_result.pkl\"\n",
    "    if os.path.isfile(log_file):\n",
    "        with open(log_file, 'rb') as handle:\n",
    "            coco_evaluate_result = pickle.load(handle)\n",
    "    else:\n",
    "        # output_folder=\"../lvis\"\n",
    "        ann_type_id=0\n",
    "        split=0\n",
    "\n",
    "        annType = ['segm', 'bbox', 'keypoints']\n",
    "        annType = annType[ann_type_id]  # specify type here\n",
    "        prefix = 'instances'\n",
    "        # dataDir = '../datasets/lvis/annotations'\n",
    "        # annFile = '%s/lvis_v0.5_val.json_common_rare' % (dataDir) # \n",
    "        \n",
    "        resFile = '%s/%s/%s.json' % (model_path, log_folder, annType)\n",
    "#         targets_fname = \"%s/%s/target.pth\" % (model_path, log_folder)\n",
    "#         if os.path.isfile(targets_fname):\n",
    "#             targets = torch.load(targets_fname)\n",
    "#         else:\n",
    "#             targets = None\n",
    "        cocoDt = cocoGt.loadRes(resFile)\n",
    "        imgIds = sorted(cocoGt.getImgIds())\n",
    "        imgIds = imgIds\n",
    "        cocoEval = COCOeval(cocoGt, cocoDt, annType) #, split=split, targets=targets\n",
    "        cocoEval.params.imgIds = imgIds\n",
    "        \n",
    "        coco_evaluate_result = cocoEval.evaluate_debug()\n",
    "        with open(log_file, \"wb\") as handle:\n",
    "            pickle.dump(coco_evaluate_result, handle)\n",
    "\n",
    "    \n",
    "    recThrs = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01) + 1, endpoint=True)\n",
    "    R = len(recThrs)\n",
    "#     coco_evaluate_result = [result for result in coco_evaluate_result if result]\n",
    "    _img_score, _img_thresholds = get_image_and_th(coco_evaluate_result, target_cat)\n",
    "    img_ids = np.array([k for k, v in _img_score.items()])\n",
    "    img_scores = np.array([v for k, v in _img_score.items()])\n",
    "    img_thresholds = np.array([v for k, v in _img_thresholds.items()])\n",
    "    inds = np.argsort(-img_scores, kind='mergesort')\n",
    "    inds = inds[0:1000]\n",
    "    img_thresholds = img_thresholds[inds]\n",
    "    img_scores = img_scores[inds]\n",
    "    test_images = img_ids[inds]\n",
    "    img_output_folder = \"outputs_lvis_{0}\".format(i)\n",
    "    # img_output_folder = img_output_folder + \"_\" + str(i)\n",
    "    save_outputs(test_images, img_thresholds, img_output_folder, cocoGt, cocoDt, target_cat)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_img_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/lvis_mil12_aff005_test/features/all_pair_df.pickle'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
